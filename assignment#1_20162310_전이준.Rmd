---
title: "Assingmet2"
author: "LeeJoon Jeon"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

### 

<br/>

#### 1. 먼저 ID와 ZIP.code는 feature에서 제외한다. 그리고 z-score normalization을 활용하여 모든 feature들의 scale을 일치시킨다. 첫 4,000명의 데이터를 training set으로, 나머지 1,000명의 데이터를 test set으로 사용하고, training set과 test set에서의 target variable의 분포를 비교해 보자.  

<br/>


```{r message=FALSE}
# 사용할 패키지 추가
library(ggplot2)
library(ggthemes)
library(class)
library(caret)
setwd('/Users/Administrator/Desktop/데분')
```

```{r graph1}
# 데이터파일 읽기
common <- read.csv('CommonBank.csv')
str(common)

#먼저 ID와 ZIP.code는 feature에서 제외
cm <- common[,-1]
cm <- cm[,-4]
str(cm)

#PersonalLoan 값 변환
cm$PersonalLoan <- factor(cm$PersonalLoan, levels = c("1","0"), labels = c("Accept","Reject"))
str(cm)

#z_core_normalizion
z_score_normalization <- function(x) {
  return ((x-mean(x))/sd(x))
}

#z_score_normalization 적용
cm_nor <- as.data.frame(lapply(cm[,-8],z_score_normalization))
str(cm_nor)
str(cm)

#training set, test set 나누기
cm_train <- cm_nor[1:4000,]
cm_test <- cm_nor[4001:5000,]
cm_train_labels <- cm[1:4000,8]
cm_test_labels <- cm[4001:5000,8]

#taget variable분포 비교
table(cm_train_labels)
397/4000

table(cm_test_labels)
83/1000
```
<br/>
####taget variable인 PersonalLoan의 Accept 비율은 training set, test set에서 각각 0.09925, 0.083으로 약 0.016차이이므로 거의 차이가 없다.


<br/>

#### 2. 5-NN을 적용하고, 결과를 분석해보자.

<br/>


```{r graph2}
#5-nn적용
cm_test_pred<- knn(train = cm_train, test=cm_test, cl=cm_train_labels, k=5)

#confusion matrix 구하기
cm_pred_matrix <- confusionMatrix(cm_test_pred, cm_test_labels)
cm_pred_matrix
```
<br/>
#### 5-NN에서 96.2%의 Accuracy, 59.04%의 Sensitivity, 99.56의 Specificity를 얻었다. 즉, 실제 대출 상품에 고객에 대한 예측은 뛰어나지만 대출 상품에 가입할 고객을 예측하는 것은떨어진다.


<br/>

#### 3.  Training set 중에서 마지막 800명의 데이터를 validation set으로 사용하여, 다양한 k 값에 대해 k-NN을 적용해 보고 예측 성능을 비교해 보자. k가 어떤 값을 가질때 모델의 성능이 가장 우수한가?

<br/>


```{r graph3}

#training set, validation set 나누기
cm_train <- cm_nor[1:3200,]
cm_train_labels <- cm[1:3200,8]
cm_val <- cm_nor[3201:4000,]
cm_val_labels <- cm[3201:4000,8]
str(cm_val)
str(cm_val_labels)

#dataframe 생성
df=data.frame(k=numeric(),accuracy=numeric(), sensitivity=numeric(), specificity = numeric())

#예측모델 생성 및 성능을 비교할 값 저장
for(i in c(1:100)) {
cm_test_pred_2 <- knn(train=cm_train, test= cm_val, cl=cm_train_labels, k= i)
matrix <- confusionMatrix(cm_test_pred_2, cm_val_labels)
df[i,"k"] <- i
df[i,"accuracy"] <- matrix$overall[1]
df[i,"sensitivity"] <- matrix$byClass[1]
df[i,"specificity"] <- matrix$byClass[2]
}
str(df)

#accuracy 최대값 
max(df$accuracy)

#accuracy 값 그래프를 통해 최대 accuracy 의 k값 구하기
ggplot(data=df, aes(x=k,y=accuracy)) + geom_point(color="blue") + geom_line() +theme_bw()

#k=1 일때 accuracy 최대
#1-NN
cm_test_pred_3<- knn(train = cm_train, test=cm_test, cl=cm_train_labels, k=1)
cm_pred_matrix_2 <- confusionMatrix(cm_test_pred_3, cm_test_labels)
cm_pred_matrix_2
```
<br/>

#### 그래프를 보면 k=1 일 때 Accuracy가 95.75%로 가장 높으므로 k=1일 때 모델이 가장 우수할 수 있다. 1-NN일 때 96.6%의 Accuracy, 73.49%의 Sensitivity, 98.69%의 Sepcificity를 가진다.

<br/>

#### 4.  Training set에 대해 5-fold cross validation을 5회 반복하여 best k 값을 찾아보자. Best k 값으로 만들어지는 최종 model에 test set을 적용하여 model의 성능을 report하자. 

<br/>

```{r graph4}
#training set, test set 나누기
cm_train <- cm[1:4000,]
cm_test <- cm[4001:5000,]
cm_train_labels <- cm[1:4000,8]
cm_test_labels <- cm[4001:5000,8]

#값이 변하지 않게 하기
set.seed(123)

#z_score_normalization
z_normalized <- c("center","scale")

#5-fold cross validation을 5회 반복
cv <- trainControl(method="repeatedcv", number =5, repeats =5)

#k값에 대해 parameter tuning
tune_grid <- expand.grid(k=seq(1,99,2))

#cv를 활용한 parameter tuning 실행
knn_fit <- train(data=cm_train, PersonalLoan~., method = "knn", trControl=cv, preProcess=z_normalized, tuneGrid=tune_grid)
knn_fit

#그래프 그리기
ggplot(knn_fit) +theme_bw()

#최종 model을 test set에 적용
cm_test_pred_4 <- predict(knn_fit, cm_test[,-8])
confusionMatrix(cm_test_pred_4, cm_test_labels)

```
<br/>

#### 5-fold cross validation을 5회 실시한 결과 k=3일 때 95.78% Accuracy 가장 뛰어난 값을 가졌다. 3-NN에 적용한 결과 96.7%의 Accuracy, 65.06%의 Sensitivity, 99.56%의 Specificity를 가졌다.



<br/>

#### 5. 3번과 4번에서 활용한 training 방식의 장단점을 비교해보자.  


<br/>

#### -3번의 경우에 데이터 수가 충분하면 큰 문제는 없겠지만 데이터 수가 부족한 경우 정확한 모델을 얻기가 힘들다.
#### -4번의 경우는 교차검증을 통해 평과 결과가 좀 더 일반화된 모델을 만들 수 있다. 또한 데이터가 부족할 때 교차검증을 활용한다면 더 좋은 모델을 찾을 수 있다. 하지만 검증 횟수가 많기 때문에 시간이 오래 걸린다는 단점이 있다.
