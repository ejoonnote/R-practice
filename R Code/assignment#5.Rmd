---
title: "Assingmet5"
author: "LeeJoon Jeon"
output:
  html_document: 
    highlight: pygments
  pdf_document: default
---

<br/>

###

<br/>

## 1. 아래의 순서에 따라 data preprocessing을 수행하자.

<br/>

### A. dslabs 패키지를 설치하고, 다음 코드를 실행하면 mnist 변수에 아래 설명과 같이 데이터가 저장된다.


```{r message=FALSE}
library(dslabs)

#데이터 저장
mnist <- dslabs::read_mnist()
```
<br/>


<br/>

### B.  Training set의 데이터 사이즈가 매우 크기 때문에 60,000개의 데이터 중에 처음 2,000개만 사용하자. 이때 feature 데이터는 변수 train_x에 저장하고, target 데이터는 변수 train_y에 저장한다. train_y의 분포를 확인해보자. 

```{r graph1}
#데이터 나누기
train_x <- mnist$train$images[1:2000,]
train_y <- mnist$train$labels[1:2000]

#train_y 분포
table(train_y)

```

<br/>

#### train_y는 0~9까지 분포해 있다.
0   |1   |2   |3   |4   |5   |6   |7   |8   |9
----|----|----|----|----|----|----|----|----|------
191 |220 |198 |191 |214 |180 |200 |224 |172 |210                

<br/>

### C.  train_x의 column의 이름을 V1, V2, V3 … 순서대로 설정하자. colnames() 함수를 사용하여 column의 이름을 수정할 수 있다. 

<br/>

```{r graph2}
#colnames
ncol(train_x)
colnames(train_x)<- paste0("v",1:784)
str(train_x)
```

<br/>


<br/>

### D. 784개의 픽셀 중에서 숫자와 관련없는 가장자리 부분과 같은 경우는 많은 데이터들에 대해서 같은 색을 가진다. 이러한 픽셀은 숫자를 분류하는 데 크게 영향을 미치지 않으므로 feature에서 제외시키는 것이 합리적이다. caret 패키지의 nearZeroVar(train_x) 함수를 실행하면 train_x의 column들 중에서 variance가 0이거나 0에 가까운 것들의 index를 얻을 수 있다. 이 index에 해당하는 column을 train_x에서 제외시키자. 784개의 feature 중에서 몇개가 제외되었는가?

<br/>

```{r graph3}
library(caret)
#column들 중에서 variance가 0이거나 0에 가까운 index
train_col_zero <- nearZeroVar(train_x)
length(train_col_zero)

#nearZeroVar에서 column의 index 제외
train_x <- subset(train_x, select = -c(train_col_zero))
str(train_x)
```

<br/>

#### 540개의 feature이 제외되었다.

<br/>

### E. 최종적으로 train_x와 train_y를 합쳐서 train이라는 이름의 데이터프레임을 만들자.

<br/>

```{r graph4}
#데이터프레임으로 합치기
train <- data.frame(train_x, train_y)
str(train)
```

<br/>



<br/>

### F. C~E의 과정을 test set에 대해서 동일하게 수행하여 test라는 이름의 데이터프레임을 만들자. 이때 D에서 제외한 feature와 동일한 feature들을 test set에서도 제외시켜야 한다.

```{r graph5}
#test set에 적용
test_x <- mnist$test$images
test_y <- mnist$test$labels

#colname
ncol(test_x)
colnames(test_x) <- paste0("v",1:784)
str(test_x)

#nearZeroVar에서 column의 index 제외
test_x <- subset(test_x, select = -c(train_col_zero))
str(test_x)

#dataframe 합치기
test <- data.frame(test_x, test_y)
str(test)
```

<br/>



<br/>

## 2. 아래의 코드는 test set의 첫번째 데이터를 화면에 이미지로 출력해준다. 이를 활용하여 test set의 image 행렬의 행 번호를 입력받아 숫자 이미지를 출력하는 함수 print_image()를 만들어보자. 이 함수를 활용하여 test set 중에서 이미지로부터 실제 숫자값을 유추하기 어려운 예를 몇 개 찾아보자.

<br/>

```{r graph6}
#print_image함수 만들기
print_image <- function(x) {image(1:28, 1:28, matrix(mnist$test$images[x,],nrow=28)[,28:1],col=gray(seq(0,1,0.05)), xlab="",ylab="")}

#유추 어려운 예
print_image(9)
test_y[9]

print_image(42)
test_y[42]
```

<br/>

#### 9번째는 실제값은 5지만 6으로 보여 유추하기 어렵고 42번째 데이터는 실제값이 7이지만 이미지만 보면 2로 보인다.

<br/>

## 3. 아래의 순서로 tree를 만들어보자

<br/>

### A. Cost complexity parameter=0 일때, leaf node가 가지는 최소 데이터의 수가 50인 Tree를 만들고 시각화해보자. Tree는 몇 개의 leaf node를 가지는가? Tree의 depth는 얼마인가?

```{r graph7}
library(rpart)
library(rpart.plot)

#factor변환
train$train_y <- as.factor(train$train_y)

#Cost complexity parameter가 0일때, leaf node가 가지는 최소 데이터의 수가 50인 Tree
set.seed(123)
ct_1 <- rpart(train_y ~., data= train, method="class", control=list(cp=0,minbucket=50))
rpart.plot(ct_1)
```

<br/>

#### 21개의 leaf node를 가지며 depth는 6이다.

<br/>

### B. Cost complexity parameter=0 일때, depth가 최대 3인 Tree를 만들고 시각화해보자. Tree는 몇개의 leaf node를 가지는가? 만들어진 tree가 실제 classification에 활용될 수 있을까?

```{r graph8}
#Cost complexity parameter가 0일때, depth가 최대 3인 Tree
set.seed(12)
ct_2 <- rpart(train_y~., data=train, method="class", contro=list(cp=0, maxdepth=3))
rpart.plot(ct_2)

printcp(ct_2)
```

<br/>

#### 8개의 leaf node를 가진다. 최대 depth를 3으로 했기 때문에 잘 분류되었다고 생각되지 않는다. 또한 xerror의 값이 작다고 볼 수 없으므로 실제 classification에 활용되기는 어렵다고 생각된다.


<br/>

### C. rpart() 함수를 사용하여 Tree를 만든 후 cross validation을 활용한 pruning 과정을 수행해보자. 

<br/>

```{r graph9}
#rpart() 함수를 사용하여 Tree
set.seed(23)
ct_3 <- rpart(train_y~., data=train, method="class")
#cross validation 결과 출력
printcp(ct_3)
#cross validation 결과 시각화
plotcp(ct_3)

#cv error가 가장 낮을 때 cp 저장
best_cp <- ct_3$cptable[which.min(ct_3$cptable[,"xerror"]),"CP"]
best_cp


#best cp 값일 때 pruned tree생성
best_ct <- prune(ct_3, cp=best_cp)
rpart.plot(best_ct)
```

<br/>

#### xerror가 가장 낮을 때의 CP는 0.01이다.이 때 15개의 leaf node가 존재한다. 


<br/>

### D. C에서 얻은 tree로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자. Test set에 대한 예측 정확도는 얼마인가? 

<br/>

```{r graph10}
#factor로 변환
test$test_y <- as.factor(test$test_y)

#test set에 대한 예측 오차 계산
pred_prob <- predict(best_ct, newdata = test, type = "prob")
pred_class <- predict(best_ct, newdata = test, type = "class")
confusionMatrix(pred_class,test$test_y)
```

<br/>

#### Accuracy는 0.5906이다. 아래 표에 Sensitiviy를 보면 분류 정확도가 높은 것은 7이고 가장 낮은 것은 5인것을 볼 수 있다.
0     |1     |2     |3     |4     |5     |6     |7     |8     |9
------|------|------|------|------|------|------|------|------|------
0.7755|0.7542|0.4399|0.4614|0.5407|0.3016|0.5908|0.8220|0.5554|0.6125

<br/>

## 4. Random Forest를 만들어보자.

<br/>

### A. randomForest() 함수를 사용하여 bagging model을 만들어보자. mtry를 제외한 옵션은 모두 default 값을 사용한다. plot() 함수를 사용하여 Bagging model에서 tree의 수의 증가에 따른 OOB classification error rate의 변화를 그래프로 출력해보자. 어떤 경향을 보이는가?

<br/>

```{r graph11}
library(randomForest)

set.seed(1234)
#bagging
bag <- randomForest(train_y ~., data=train, mtry=ncol(train)-1)
bag

#training set에 대한 out-of-bag prediction 계산
head(bag$predicted)
head(bag$err.rate)
plot(bag)
plot(bag$err.rate[,1], xlab = "tree", ylab = "OOB classification error rate")
```

<br/>

#### tree수가 적을 때는 OOB classification error rate가 tree 수가 많아질수록 급격하게 감소하다가 tree개수가 100개에 가까워질수록 감소하는 폭이 작아지며 그 이후에는 거의 비슷한 값을 가진다. 

<br/>

### B. Bagging model로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자. Test set에 대한 예측 정확도는 얼마인가? 3번에서 계산한 tree model에 비해서 성능이 얼마나 향상되었는가?

<br/>

```{r graph12}
#bagging모델의 test set에 대한 예측 및 confusionmatrix계산
pred_bag <- predict(bag, newdata=test, type = "class")
confusionMatrix(pred_bag, test$test_y)
```

<br/>

#### bagging model의 Accuracy는 0.8951이다. 3번에서 pruning한 model의 Accuracy는 0.5906으로 Accuracy가 0.3045만큼 향상되었다.

<br/>

### C. randomForest() 함수의 default 옵션을 사용하여 random forest model을 만들어보자. 그리고 Bagging과 random forest 모델의 Tree의 수의 증가에 따른 OOB classification error rate의 변화를 하나의 그래프에 그려보고 두 모델의 성능을 비교해보자. 

<br/>

```{r graph13}
#randomforest model
set.seed(12345)
rf <- randomForest(train_y ~., data=train)
rf
str(bag$err.rate[,1])

#data frame생성
frame_error <- data.frame(a = 1:500, bag_error = bag$err.rate[,1], rf_error = rf$err.rate[,1])

#bagging, randomforest OOB classification error rate 비교 그래프
#bagging은 파란색, randomforest는 빨강
ggplot() + geom_point(data=frame_error, aes(x=a, y=bag_error), color = "blue", size=0.3) + geom_point(data=frame_error, aes(x=a,y=rf_error), color= "red", size= 0.3) + labs(x = "tree", y = "OOB classification error rate")

```

<br/>

#### bagging model이 파랑, randomforest model이 빨강이다. 그래프를 보면 OOB classification rate가 두 모델간 크게 차이가 나지 않는 것을 볼 수 있다. 하지만 tree의 수가 많아질수록 randomforest model의 OOB classification error rate가 조금 더 낮은 것을 볼 수 있다. 따라서 tree의 수가 많을수록 randomforest model이 bagging model 보다 좀 더 우수하다고 볼 수 있다.


<br/>

### D. Random forest model로 test set에 대한 예측을 수행하고, confusion matrix를 계산해보자. Test set에 대한 예측 정확도는 얼마인가? Bagging model에 비해서 성능이 얼마나 향상되었는가?

<br/>

```{r graph14}
#randomforest모델의 test set에 대한 예측 및 confusionmatrix계산
pred_rf <- predict(rf, newdata =test, type = "class")
confusionMatrix(pred_rf, test$test_y)
```

<br/>

#### Accuracy가 0.9112이다. bagging model의 Accuracy는 0.8951으로 bagging model보다 Accuracy가 0.0161이 향상되었다.


<br/>

### E. D번의 confusion matrix 결과로부터, 분류가 가장 정확한 숫자는 몇인가? 가장 분류가 어려운 숫자는 몇인가?

<br/>

#### sensitivity가 가장 높은 것은 class 1이고 가장 낮은 것은 class 8이므로 분류가 가장 정확한 숫자는 1이고 어려운 숫자는 8이다.
0     |1     |2     |3     |4     |5     |6     |7     |8     |9
------|------|------|------|------|------|------|------|------|------
0.9735|0.9797|0.9041|0.8673|0.8982|0.8845|0.9228|0.9056|0.8491|0.9158    

<br/>

### F. 실제 값은 7이지만 Random forest model에 의해 1로 예측되는 test data를 찾아 이미지를 몇 개 출력해보자. 눈으로 확인했을 때 7과 1의 구별이 어려운가?

<br/>

```{r graph15}
#구별이 어려운 test data
which(test$test_y == "7" & pred_rf == "1")

print_image(552)
print_image(1261)
print_image(1501)
```
<br/>

#### 데이터를 확인해보면 1261번째 data는 제외한 552,1501번째 data는 7과 1의 구별에서는 7로 보인다. 1261번째 data는 1로도 보여진다. 하지만 552,1501번째 data가 무조건 7로 보이지는 않는다.

<br/>


